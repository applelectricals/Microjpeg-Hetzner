SIMPLE SEQUENTIAL PROCESSING - FULL IMPLEMENTATION

1. BACKEND: UPDATE SERVER.JS
const express = require('express');
const fileUpload = require('express-fileupload');
const cors = require('cors');
const sharp = require('sharp');
const { S3Client, PutObjectCommand, GetObjectCommand } = require('@aws-sdk/client-s3');
const app = express();

// CORS
app.use(cors({
  origin: process.env.FRONTEND_URL || '*',
  credentials: true
}));

// Body parser with limits
app.use(express.json({ limit: '250mb' }));
app.use(express.urlencoded({ limit: '250mb', extended: true }));

// File upload middleware
app.use(fileUpload({
  limits: { fileSize: 200 * 1024 * 1024 }, // 200MB max
  useTempFiles: true,
  tempFileDir: '/tmp/',
  debug: false,
  abortOnLimit: false,
  uploadTimeout: 600000 // 10 minutes
}));

// R2 Client Configuration
const r2Client = new S3Client({
  region: 'auto',
  endpoint: `https://${process.env.R2_ACCOUNT_ID}.r2.cloudflarestorage.com`,
  credentials: {
    accessKeyId: process.env.R2_ACCESS_KEY_ID,
    secretAccessKey: process.env.R2_SECRET_ACCESS_KEY,
  },
});

// In-memory storage for file metadata (replace with database in production)
const fileStore = new Map();

// =============================================================================
// UPLOAD ENDPOINT - Uploads file and auto-converts to JPG
// =============================================================================

app.post('/api/upload', async (req, res) => {
  const startTime = Date.now();
  
  try {
    const file = req.files?.image;
    
    if (!file) {
      return res.status(400).json({ error: 'No file uploaded' });
    }
    
    // Validate file size based on user plan
    const userPlan = req.body.plan || 'free'; // Get from auth middleware
    const maxSize = getMaxFileSize(userPlan);
    
    if (file.size > maxSize) {
      return res.status(413).json({ 
        error: 'File too large',
        maxSize: maxSize,
        fileSize: file.size
      });
    }
    
    // Generate unique file ID
    const fileId = Date.now() + '-' + Math.random().toString(36).substr(2, 9);
    
    console.log(`ðŸ“¥ Upload: ${file.name} (${(file.size / 1024 / 1024).toFixed(2)}MB) - ID: ${fileId}`);
    
    // Upload original to R2
    const originalKey = `uploads/${fileId}/original/${file.name}`;
    await uploadToR2(file.data, originalKey, 'original');
    
    console.log(`âœ… Uploaded to R2: ${originalKey}`);
    
    // Store file metadata
    fileStore.set(fileId, {
      id: fileId,
      originalName: file.name,
      originalSize: file.size,
      originalKey: originalKey,
      uploadedAt: new Date().toISOString(),
      formats: {}, // Will store completed formats here
      userId: req.user?.id || 'anonymous'
    });
    
    // Auto-convert to JPG
    console.log(`ðŸ”„ Auto-converting to JPG...`);
    
    try {
      const jpgResult = await processFile(fileId, 'jpg');
      
      const uploadTime = ((Date.now() - startTime) / 1000).toFixed(2);
      
      res.json({
        success: true,
        fileId: fileId,
        fileName: file.name,
        originalSize: file.size,
        uploadTime: uploadTime + 's',
        jpg: jpgResult
      });
      
    } catch (jpgError) {
      console.error('JPG conversion failed:', jpgError);
      res.status(500).json({
        error: 'JPG conversion failed',
        message: jpgError.message,
        fileId: fileId // Still return fileId so user can retry
      });
    }
    
  } catch (error) {
    console.error('âŒ Upload error:', error);
    res.status(500).json({ 
      error: 'Upload failed',
      message: error.message 
    });
  }
});

// =============================================================================
// CONVERT ENDPOINT - Converts files to additional format (ONE AT A TIME)
// =============================================================================

app.post('/api/convert', async (req, res) => {
  const startTime = Date.now();
  
  try {
    const { fileIds, format } = req.body;
    
    // Validation
    if (!fileIds || !Array.isArray(fileIds) || fileIds.length === 0) {
      return res.status(400).json({ error: 'fileIds must be a non-empty array' });
    }
    
    if (!format || !['png', 'webp', 'avif', 'tiff'].includes(format.toLowerCase())) {
      return res.status(400).json({ 
        error: 'Invalid format',
        validFormats: ['png', 'webp', 'avif', 'tiff']
      });
    }
    
    console.log(`\nðŸŽ¯ Converting ${fileIds.length} file(s) to ${format.toUpperCase()}`);
    console.log(`ðŸ“‹ File IDs: ${fileIds.join(', ')}`);
    
    const results = [];
    
    // ==========================================
    // SEQUENTIAL PROCESSING - ONE FILE AT A TIME
    // ==========================================
    
    for (let i = 0; i < fileIds.length; i++) {
      const fileId = fileIds[i];
      
      console.log(`\n[${i + 1}/${fileIds.length}] Processing ${fileId}...`);
      
      try {
        const result = await processFile(fileId, format);
        results.push(result);
        
        console.log(`âœ… [${i + 1}/${fileIds.length}] Completed: ${result.fileName} â†’ ${format.toUpperCase()} (${result.processingTime})`);
        
      } catch (error) {
        console.error(`âŒ [${i + 1}/${fileIds.length}] Failed ${fileId}:`, error.message);
        
        results.push({
          fileId,
          format: format.toUpperCase(),
          status: 'failed',
          error: error.message
        });
      }
    }
    
    const totalTime = ((Date.now() - startTime) / 1000).toFixed(2);
    
    console.log(`\nâœ… All conversions complete in ${totalTime}s`);
    
    res.json({
      success: true,
      format: format.toUpperCase(),
      totalFiles: fileIds.length,
      totalTime: totalTime + 's',
      results
    });
    
  } catch (error) {
    console.error('âŒ Convert error:', error);
    res.status(500).json({ 
      error: 'Conversion failed',
      message: error.message 
    });
  }
});

// =============================================================================
// GET FILE STATUS - Check what formats are available for a file
// =============================================================================

app.get('/api/file/:fileId', async (req, res) => {
  try {
    const { fileId } = req.params;
    
    const fileData = fileStore.get(fileId);
    
    if (!fileData) {
      return res.status(404).json({ error: 'File not found' });
    }
    
    res.json({
      success: true,
      file: fileData
    });
    
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// =============================================================================
// CORE PROCESSING FUNCTION
// =============================================================================

async function processFile(fileId, format) {
  const processStart = Date.now();
  
  // Get file metadata
  const fileData = fileStore.get(fileId);
  
  if (!fileData) {
    throw new Error(`File ${fileId} not found`);
  }
  
  // Check if this format already exists
  if (fileData.formats[format]) {
    console.log(`â­ï¸  ${fileData.originalName} already has ${format.toUpperCase()}`);
    return {
      fileId,
      fileName: fileData.originalName,
      format: format.toUpperCase(),
      status: 'exists',
      size: fileData.formats[format].size,
      url: fileData.formats[format].url,
      processingTime: '0s (cached)'
    };
  }
  
  console.log(`ðŸ”„ Converting ${fileData.originalName} â†’ ${format.toUpperCase()}...`);
  
  // Download original file from R2
  const originalBuffer = await downloadFromR2(fileData.originalKey);
  
  // Convert to target format
  const outputBuffer = await convertToFormat(originalBuffer, format);
  
  console.log(`ðŸ“¦ Output size: ${(outputBuffer.length / 1024 / 1024).toFixed(2)}MB`);
  
  // Upload to R2
  const outputKey = `processed/${fileId}/${format}/${Date.now()}.${format}`;
  await uploadToR2(outputBuffer, outputKey, format);
  
  // Store format completion in metadata
  fileData.formats[format] = {
    size: outputBuffer.length,
    url: `${process.env.R2_PUBLIC_URL || ''}/${outputKey}`,
    r2Key: outputKey,
    createdAt: new Date().toISOString()
  };
  
  fileStore.set(fileId, fileData);
  
  const processingTime = ((Date.now() - processStart) / 1000).toFixed(2);
  
  return {
    fileId,
    fileName: fileData.originalName,
    format: format.toUpperCase(),
    status: 'success',
    size: outputBuffer.length,
    sizeHuman: (outputBuffer.length / 1024 / 1024).toFixed(2) + ' MB',
    originalSize: fileData.originalSize,
    savings: ((1 - outputBuffer.length / fileData.originalSize) * 100).toFixed(1) + '%',
    url: fileData.formats[format].url,
    processingTime: processingTime + 's'
  };
}

// =============================================================================
// IMAGE CONVERSION FUNCTION
// =============================================================================

async function convertToFormat(buffer, format) {
  // Configure Sharp for large images
  let pipeline = sharp(buffer, {
    unlimited: true,
    sequentialRead: true,
    failOnError: false
  });
  
  switch(format.toLowerCase()) {
    case 'jpg':
    case 'jpeg':
      return await pipeline
        .jpeg({ 
          quality: 82,
          progressive: true,
          mozjpeg: true,
          optimizeScans: true,
          trellisQuantisation: true,
          overshootDeringing: true
        })
        .toBuffer();
    
    case 'png':
      // PNG can expand, so optimize aggressively
      return await pipeline
        .png({ 
          compressionLevel: 9,
          adaptiveFiltering: true,
          palette: true,  // Use indexed color when possible
          quality: 90,
          effort: 10
        })
        .toBuffer();
    
    case 'webp':
      return await pipeline
        .webp({ 
          quality: 82,
          effort: 6,
          smartSubsample: true
        })
        .toBuffer();
    
    case 'avif':
      return await pipeline
        .avif({ 
          quality: 65,
          effort: 2,  // Balance speed/quality
          chromaSubsampling: '4:2:0',
          speed: 8
        })
        .toBuffer();
    
    case 'tiff':
      return await pipeline
        .tiff({ 
          compression: 'jpeg',  // JPEG compression for smaller files
          quality: 85
        })
        .toBuffer();
    
    default:
      throw new Error(`Unsupported format: ${format}`);
  }
}

// =============================================================================
// R2 HELPER FUNCTIONS
// =============================================================================

async function uploadToR2(buffer, key, format) {
  await r2Client.send(new PutObjectCommand({
    Bucket: process.env.R2_BUCKET_NAME,
    Key: key,
    Body: buffer,
    ContentType: getContentType(format),
    CacheControl: 'public, max-age=31536000', // 1 year
  }));
}

async function downloadFromR2(key) {
  const response = await r2Client.send(new GetObjectCommand({
    Bucket: process.env.R2_BUCKET_NAME,
    Key: key,
  }));
  
  const chunks = [];
  for await (const chunk of response.Body) {
    chunks.push(chunk);
  }
  
  return Buffer.concat(chunks);
}

function getContentType(format) {
  const types = {
    jpg: 'image/jpeg',
    jpeg: 'image/jpeg',
    png: 'image/png',
    webp: 'image/webp',
    avif: 'image/avif',
    tiff: 'image/tiff',
    original: 'application/octet-stream'
  };
  return types[format.toLowerCase()] || 'application/octet-stream';
}

// =============================================================================
// HELPER FUNCTIONS
// =============================================================================

function getMaxFileSize(plan) {
  const limits = {
    free: 15 * 1024 * 1024,        // 15MB
    starter: 75 * 1024 * 1024,     // 75MB
    pro: 150 * 1024 * 1024,        // 150MB
    business: 200 * 1024 * 1024    // 200MB
  };
  return limits[plan.toLowerCase()] || limits.free;
}

// =============================================================================
// HEALTH CHECK
// =============================================================================

app.get('/health', (req, res) => {
  res.json({ 
    status: 'ok',
    uptime: process.uptime(),
    filesInMemory: fileStore.size
  });
});

// =============================================================================
// ERROR HANDLER
// =============================================================================

app.use((err, req, res, next) => {
  console.error('Global error handler:', err);
  
  if (!res.headersSent) {
    res.status(500).json({
      error: 'Internal server error',
      message: process.env.NODE_ENV === 'production' ? 'Something went wrong' : err.message
    });
  }
});

// =============================================================================
// START SERVER
// =============================================================================

const PORT = process.env.PORT || 3000;

const server = app.listen(PORT, () => {
  console.log(`ðŸš€ Server running on port ${PORT}`);
  console.log(`ðŸ“ R2 Bucket: ${process.env.R2_BUCKET_NAME}`);
  console.log(`ðŸŒ Public URL: ${process.env.R2_PUBLIC_URL || 'Not set'}`);
});

// Increase timeouts
server.timeout = 600000;           // 10 minutes
server.keepAliveTimeout = 610000;
server.headersTimeout = 620000;

// Graceful shutdown
process.on('SIGTERM', () => {
  console.log('SIGTERM received, shutting down gracefully...');
  server.close(() => {
    console.log('Server closed');
    process.exit(0);
  });
});

// Handle unhandled promise rejections
process.on('unhandledRejection', (reason, promise) => {
  console.error('Unhandled Rejection at:', promise, 'reason:', reason);
});

2. PACKAGE.JSON

{
  "name": "microjpeg-server",
  "version": "1.0.0",
  "description": "Image processing API",
  "main": "server.js",
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js"
  },
  "dependencies": {
    "express": "^4.18.2",
    "express-fileupload": "^1.4.3",
    "cors": "^2.8.5",
    "sharp": "^0.33.1",
    "@aws-sdk/client-s3": "^3.478.0",
    "dotenv": "^16.3.1"
  },
  "devDependencies": {
    "nodemon": "^3.0.2"
  }
}

3. FRONTEND INTEGRATION
Upload File:

async function uploadFile(file) {
  const formData = new FormData();
  formData.append('image', file);
  formData.append('plan', 'starter'); // or get from user session
  
  const response = await fetch('https://microjpeg.com/api/upload', {
    method: 'POST',
    body: formData
  });
  
  const result = await response.json();
  
  if (result.success) {
    console.log('File uploaded:', result.fileId);
    console.log('JPG ready:', result.jpg.url);
    
    // Store fileId for later conversions
    return result;
  }
}

Convert to Additional Format:

async function convertToFormat(fileIds, format) {
  // Show loading state
  showLoading(`Converting ${fileIds.length} file(s) to ${format.toUpperCase()}...`);
  
  const response = await fetch('https://microjpeg.com/api/convert', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      fileIds: fileIds,  // e.g., ['file1-id', 'file2-id']
      format: format     // e.g., 'png'
    })
  });
  
  const result = await response.json();
  
  hideLoading();
  
  if (result.success) {
    console.log(`âœ… Converted ${result.totalFiles} files in ${result.totalTime}`);
    
    // Update UI with results
    result.results.forEach(fileResult => {
      if (fileResult.status === 'success') {
        updateFileUI(fileResult.fileId, format, fileResult.url);
      } else {
        showError(`Failed to convert ${fileResult.fileName}: ${fileResult.error}`);
      }
    });
  }
}


Example UI Integration:

// When user clicks PNG button
document.getElementById('btn-png').addEventListener('click', async () => {
  const fileIds = getUploadedFileIds(); // Get all uploaded file IDs
  
  if (fileIds.length === 0) {
    alert('Please upload files first');
    return;
  }
  
  try {
    await convertToFormat(fileIds, 'png');
  } catch (error) {
    console.error('Conversion failed:', error);
    alert('Conversion failed. Please try again.');
  }
});










